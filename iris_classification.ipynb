{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset:\n",
        "Fisher, R. (1936). Iris [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C56C76."
      ],
      "metadata": {
        "id": "_e8-rGupjw7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "6zOwNn_VjqG8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CZ3_SoZMbcl2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler,normalize\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "bgRRdG7ujln2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
        "df = pd.read_csv('iris.data', names=cols)\n",
        "df['class'] = df['class'].map({'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2})\n",
        "train, val, test = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
        "\n",
        "def scale_dataset(dataframe):\n",
        "  X = dataframe[dataframe.columns[:-1]].values\n",
        "  y = dataframe[dataframe.columns[-1]].values\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  X = scaler.fit_transform(X)\n",
        "\n",
        "  data = np.hstack((X, np.reshape(y, (-1, 1))))\n",
        "\n",
        "  return data, X, y\n",
        "\n",
        "train, X_train, y_train = scale_dataset(train)\n",
        "val, X_val, y_val = scale_dataset(val)\n",
        "test, X_test, y_test = scale_dataset(test)\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_val = tf.keras.utils.to_categorical(y_val)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KWRwvNTeFn4",
        "outputId": "5bb10663-749c-447e-9f19-67c4c9eab9d0",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network"
      ],
      "metadata": {
        "id": "6fdceC46k9H_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(X_train, y_train, num_nodes, dropout_prob, lr, batch_size, epochs):\n",
        "  nn_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(num_nodes, activation=\"sigmoid\", input_shape=(4,)),\n",
        "    tf.keras.layers.Dropout(dropout_prob),\n",
        "    tf.keras.layers.Dense(num_nodes, activation=\"sigmoid\"),\n",
        "    tf.keras.layers.Dropout(dropout_prob),\n",
        "    tf.keras.layers.Dense(3, activation=\"softmax\")\n",
        "  ])\n",
        "\n",
        "  nn_model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss='categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "  history = nn_model.fit(\n",
        "      X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0\n",
        "  )\n",
        "  return history, nn_model"
      ],
      "metadata": {
        "id": "BAYE3sRklOSP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "least_val_loss = float('inf')\n",
        "least_loss_model = None\n",
        "for num_nodes in [16, 32, 64]:\n",
        "  for dropout_prob in [0, 0.2]:\n",
        "    for lr in [0.01, 0.005, 0.001]:\n",
        "      for batch_size in [32, 64, 128]:\n",
        "        history, model = train_model(X_train, y_train, num_nodes, dropout_prob, lr, batch_size, epochs)\n",
        "        val_loss = model.evaluate(X_val, y_val)[0]\n",
        "        print(f\"{num_nodes} nodes, dropout {dropout_prob}, lr {lr}, batch size {batch_size}, val loss {val_loss}\")\n",
        "        if val_loss < least_val_loss:\n",
        "          least_val_loss = val_loss\n",
        "          least_loss_model = model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VIsBHaRlQPw",
        "outputId": "b0ddd90b-b828-48ba-857c-9a82b1d31939"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9333 - loss: 0.8554\n",
            "16 nodes, dropout 0, lr 0.01, batch size 32, val loss 0.8553673028945923\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7333 - loss: 0.8843\n",
            "16 nodes, dropout 0, lr 0.01, batch size 64, val loss 0.8843175172805786\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6000 - loss: 0.9853\n",
            "16 nodes, dropout 0, lr 0.01, batch size 128, val loss 0.985338568687439\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6333 - loss: 0.9347\n",
            "16 nodes, dropout 0, lr 0.005, batch size 32, val loss 0.934740424156189\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5333 - loss: 1.0216\n",
            "16 nodes, dropout 0, lr 0.005, batch size 64, val loss 1.0215505361557007\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3000 - loss: 1.1689\n",
            "16 nodes, dropout 0, lr 0.005, batch size 128, val loss 1.1689298152923584\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.3000 - loss: 1.1110\n",
            "16 nodes, dropout 0, lr 0.001, batch size 32, val loss 1.110954761505127\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3000 - loss: 1.2220\n",
            "16 nodes, dropout 0, lr 0.001, batch size 64, val loss 1.221950650215149\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4000 - loss: 1.1156\n",
            "16 nodes, dropout 0, lr 0.001, batch size 128, val loss 1.1155892610549927\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6000 - loss: 0.7799\n",
            "16 nodes, dropout 0.2, lr 0.01, batch size 32, val loss 0.7799021005630493\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6333 - loss: 0.9377\n",
            "16 nodes, dropout 0.2, lr 0.01, batch size 64, val loss 0.9376927614212036\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7333 - loss: 0.9309\n",
            "16 nodes, dropout 0.2, lr 0.01, batch size 128, val loss 0.9308826327323914\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6000 - loss: 0.9937\n",
            "16 nodes, dropout 0.2, lr 0.005, batch size 32, val loss 0.9937170743942261\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9333 - loss: 1.0109\n",
            "16 nodes, dropout 0.2, lr 0.005, batch size 64, val loss 1.010855793952942\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.3000 - loss: 1.0598\n",
            "16 nodes, dropout 0.2, lr 0.005, batch size 128, val loss 1.0597862005233765\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4000 - loss: 1.0930\n",
            "16 nodes, dropout 0.2, lr 0.001, batch size 32, val loss 1.0929921865463257\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.3000 - loss: 1.2122\n",
            "16 nodes, dropout 0.2, lr 0.001, batch size 64, val loss 1.2122268676757812\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4000 - loss: 1.0928\n",
            "16 nodes, dropout 0.2, lr 0.001, batch size 128, val loss 1.0928096771240234\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9000 - loss: 0.5419\n",
            "32 nodes, dropout 0, lr 0.01, batch size 32, val loss 0.5419164299964905\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6000 - loss: 0.7949\n",
            "32 nodes, dropout 0, lr 0.01, batch size 64, val loss 0.7949362397193909\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6000 - loss: 0.8468\n",
            "32 nodes, dropout 0, lr 0.01, batch size 128, val loss 0.846820056438446\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6000 - loss: 0.8682\n",
            "32 nodes, dropout 0, lr 0.005, batch size 32, val loss 0.8681725859642029\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7000 - loss: 0.9438\n",
            "32 nodes, dropout 0, lr 0.005, batch size 64, val loss 0.9438101649284363\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5667 - loss: 1.0581\n",
            "32 nodes, dropout 0, lr 0.005, batch size 128, val loss 1.0581488609313965\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.3667 - loss: 1.0517\n",
            "32 nodes, dropout 0, lr 0.001, batch size 32, val loss 1.051700472831726\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7000 - loss: 1.0557\n",
            "32 nodes, dropout 0, lr 0.001, batch size 64, val loss 1.0556747913360596\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 1.0893\n",
            "32 nodes, dropout 0, lr 0.001, batch size 128, val loss 1.089293360710144\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8667 - loss: 0.7021\n",
            "32 nodes, dropout 0.2, lr 0.01, batch size 32, val loss 0.7020830512046814\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6000 - loss: 0.7751\n",
            "32 nodes, dropout 0.2, lr 0.01, batch size 64, val loss 0.7751265168190002\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9000 - loss: 0.8776\n",
            "32 nodes, dropout 0.2, lr 0.01, batch size 128, val loss 0.877636730670929\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8333 - loss: 0.8505\n",
            "32 nodes, dropout 0.2, lr 0.005, batch size 32, val loss 0.8505437970161438\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6000 - loss: 0.9543\n",
            "32 nodes, dropout 0.2, lr 0.005, batch size 64, val loss 0.9542979001998901\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6333 - loss: 0.9896\n",
            "32 nodes, dropout 0.2, lr 0.005, batch size 128, val loss 0.9896446466445923\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5667 - loss: 1.0146\n",
            "32 nodes, dropout 0.2, lr 0.001, batch size 32, val loss 1.0146033763885498\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6667 - loss: 1.0594\n",
            "32 nodes, dropout 0.2, lr 0.001, batch size 64, val loss 1.059417486190796\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4000 - loss: 1.1318\n",
            "32 nodes, dropout 0.2, lr 0.001, batch size 128, val loss 1.1318002939224243\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9333 - loss: 0.3637\n",
            "64 nodes, dropout 0, lr 0.01, batch size 32, val loss 0.3637048900127411\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6000 - loss: 0.6753\n",
            "64 nodes, dropout 0, lr 0.01, batch size 64, val loss 0.6752796173095703\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.3000 - loss: 0.9648\n",
            "64 nodes, dropout 0, lr 0.01, batch size 128, val loss 0.964840292930603\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8000 - loss: 0.5346\n",
            "64 nodes, dropout 0, lr 0.005, batch size 32, val loss 0.5345664620399475\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.8506\n",
            "64 nodes, dropout 0, lr 0.005, batch size 64, val loss 0.8506124019622803\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6000 - loss: 0.9727\n",
            "64 nodes, dropout 0, lr 0.005, batch size 128, val loss 0.9727174043655396\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6000 - loss: 1.0487\n",
            "64 nodes, dropout 0, lr 0.001, batch size 32, val loss 1.0486756563186646\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.3000 - loss: 1.0832\n",
            "64 nodes, dropout 0, lr 0.001, batch size 64, val loss 1.0831831693649292\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3000 - loss: 1.0883\n",
            "64 nodes, dropout 0, lr 0.001, batch size 128, val loss 1.0883023738861084\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6333 - loss: 0.5131\n",
            "64 nodes, dropout 0.2, lr 0.01, batch size 32, val loss 0.5130540132522583\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7000 - loss: 0.7360\n",
            "64 nodes, dropout 0.2, lr 0.01, batch size 64, val loss 0.7359583377838135\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7000 - loss: 0.8744\n",
            "64 nodes, dropout 0.2, lr 0.01, batch size 128, val loss 0.8744340538978577\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4667 - loss: 0.7864\n",
            "64 nodes, dropout 0.2, lr 0.005, batch size 32, val loss 0.7863784432411194\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7000 - loss: 0.8978\n",
            "64 nodes, dropout 0.2, lr 0.005, batch size 64, val loss 0.8977798223495483\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6000 - loss: 0.9394\n",
            "64 nodes, dropout 0.2, lr 0.005, batch size 128, val loss 0.939434289932251\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 1.0537\n",
            "64 nodes, dropout 0.2, lr 0.001, batch size 32, val loss 1.0536924600601196\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3000 - loss: 1.0657\n",
            "64 nodes, dropout 0.2, lr 0.001, batch size 64, val loss 1.065743327140808\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3000 - loss: 1.1024\n",
            "64 nodes, dropout 0.2, lr 0.001, batch size 128, val loss 1.1023918390274048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = least_loss_model.predict(X_test)\n",
        "y_pred = np.round(y_pred)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExMYzTfNm_2w",
        "outputId": "b8691ee0-ad56-4940-8427-59dee8b18f33"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.80      0.80      0.80        10\n",
            "           2       0.89      0.80      0.84        10\n",
            "\n",
            "   micro avg       0.90      0.87      0.88        30\n",
            "   macro avg       0.90      0.87      0.88        30\n",
            "weighted avg       0.90      0.87      0.88        30\n",
            " samples avg       0.87      0.87      0.87        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eyhVBd5Y6y4g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}